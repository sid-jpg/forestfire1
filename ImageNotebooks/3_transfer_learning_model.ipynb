{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Fire Detection - Transfer Learning Model\n",
    "\n",
    "This notebook implements transfer learning by first training on the Github dataset and then fine-tuning on the Mendley dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set paths for Linux environment\n",
    "GITHUB_PATH = '../Data/ImageDataset/Github'\n",
    "MENDLEY_PATH = '../Data/ImageDataset/Mendley/Forest Fire Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build base model using ResNet50\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Training on Github Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare Github dataset\n",
    "github_train = train_datagen.flow_from_directory(\n",
    "    os.path.join(GITHUB_PATH, 'train'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "github_valid = valid_datagen.flow_from_directory(\n",
    "    os.path.join(GITHUB_PATH, 'valid'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Train on Github dataset\n",
    "github_history = model.fit(\n",
    "    github_train,\n",
    "    epochs=30,\n",
    "    validation_data=github_valid,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Fine-tuning on Mendley Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Unfreeze some layers of the base model\n",
    "for layer in model.layers[0].layers[-30:]:  # Unfreeze last 30 layers of ResNet50\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare Mendley dataset\n",
    "mendley_train = train_datagen.flow_from_directory(\n",
    "    os.path.join(MENDLEY_PATH, 'train'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "mendley_valid = valid_datagen.flow_from_directory(\n",
    "    os.path.join(MENDLEY_PATH, 'valid'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "mendley_test = test_datagen.flow_from_directory(\n",
    "    os.path.join(MENDLEY_PATH, 'test'),\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Fine-tune on Mendley dataset\n",
    "mendley_history = model.fit(\n",
    "    mendley_train,\n",
    "    epochs=20,\n",
    "    validation_data=mendley_valid,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot combined training history\n",
    "def plot_combined_history(github_history, mendley_history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Combine histories\n",
    "    total_epochs = len(github_history.history['accuracy']) + len(mendley_history.history['accuracy'])\n",
    "    epochs_range = range(1, total_epochs + 1)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(range(1, len(github_history.history['accuracy']) + 1),\n",
    "             github_history.history['accuracy'],\n",
    "             label='Github Training')\n",
    "    ax1.plot(range(1, len(github_history.history['val_accuracy']) + 1),\n",
    "             github_history.history['val_accuracy'],\n",
    "             label='Github Validation')\n",
    "    ax1.plot(range(len(github_history.history['accuracy']) + 1,\n",
    "                   total_epochs + 1),\n",
    "             mendley_history.history['accuracy'],\n",
    "             label='Mendley Training')\n",
    "    ax1.plot(range(len(github_history.history['accuracy']) + 1,\n",
    "                   total_epochs + 1),\n",
    "             mendley_history.history['val_accuracy'],\n",
    "             label='Mendley Validation')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(range(1, len(github_history.history['loss']) + 1),\n",
    "             github_history.history['loss'],\n",
    "             label='Github Training')\n",
    "    ax2.plot(range(1, len(github_history.history['val_loss']) + 1),\n",
    "             github_history.history['val_loss'],\n",
    "             label='Github Validation')\n",
    "    ax2.plot(range(len(github_history.history['loss']) + 1,\n",
    "                   total_epochs + 1),\n",
    "             mendley_history.history['loss'],\n",
    "             label='Mendley Training')\n",
    "    ax2.plot(range(len(github_history.history['loss']) + 1,\n",
    "                   total_epochs + 1),\n",
    "             mendley_history.history['val_loss'],\n",
    "             label='Mendley Validation')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_combined_history(github_history, mendley_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate final model\n",
    "test_loss, test_accuracy = model.evaluate(mendley_test)\n",
    "print(f'Final test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Save the final model\n",
    "model.save('../models/transfer_learning_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 }
}
